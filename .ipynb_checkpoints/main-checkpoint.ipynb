{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a75683c-024c-4262-b7a8-8c380a7bbc01",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Architecture of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a2aa5c-e31d-4842-863b-a483d000941e",
   "metadata": {},
   "source": [
    "![image.png](architecture.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48bfacc-6fd5-4967-8018-ee5ea6f536dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c37d3218-7b43-4015-9244-98940c0881b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter \n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain import PromptTemplate\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.llms import CTransformers\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaf7cc1-5f82-40db-8b8d-0f8e0e2b0e23",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loading Pdf Documents and Creating vector store\n",
    "In summary, this code demonstrates a process for loading PDF documents, splitting their content into smaller text chunks, generating embeddings using a pre-trained model, and creating a FAISS vector store from these embeddings. The resulting vector store can be used for efficient text retrieval and similarity search tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d585f6bb-092b-4c14-8970-ffec729614dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the PDF document \n",
    "DATA_PATH = 'pdf/'\n",
    "DB_FAISS_PATH = 'vectorstore/db_faiss'\n",
    "\n",
    "loader = DirectoryLoader(DATA_PATH,\n",
    "                         glob='*.pdf',\n",
    "                         loader_cls=PyPDFLoader)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bcf68b-430a-47ad-b2d3-a0997c40a59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A RecursiveCharacterTextSplitter object is created to split the loaded documents into smaller chunks of text. \n",
    "# The chunk_size parameter specifies the maximum size of each text chunk (500 characters), and the chunk_overlap parameter defines the overlap between \n",
    "# consecutive chunks (50 characters).\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500,\n",
    "                                               chunk_overlap=50)\n",
    "\n",
    "# The split_documents method is then used to split the loaded documents into text chunks.\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804bb282-6c99-4672-9192-0b6a8b5ce051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
    "                                   model_kwargs={'device': 'cpu'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27554c1-8348-451b-a3c9-025bfe1db681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A FAISS vector store is created from the generated text embeddings and the split texts. The FAISS.from_documents method takes in the text chunks \n",
    "# and their corresponding embeddings to build the vector store.\n",
    "db = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "# the save_local method is used to save the FAISS vector store to the specified path (DB_FAISS_PATH).\n",
    "db.save_local(DB_FAISS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54d1b54-359b-4209-8960-e0c5eb7809c5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Chatbot setup \n",
    "Overall, this code sets up a system that uses embeddings, a FAISS vector store, and a language model to generate responses to user questions based on provided context and questions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85e89c06-7f19-4602-ab41-a18899b14689",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_FAISS_PATH = 'vectorstore/db_faiss'\n",
    "\n",
    "custom_prompt_template = \"\"\"Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\"\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", model_kwargs={'device': 'cpu'})\n",
    "db = FAISS.load_local(DB_FAISS_PATH, embeddings)\n",
    "llm = CTransformers(\n",
    "    model = \"../llama-2-7b-chat.ggmlv3.q8_0.bin\",\n",
    "    model_type=\"llama\",\n",
    "    max_new_tokens = 512,\n",
    "    temperature = 0.5\n",
    ")\n",
    "qa_prompt = PromptTemplate(template=custom_prompt_template, input_variables=['context', 'question'])\n",
    "qa_bot = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                chain_type='stuff',\n",
    "                                retriever=db.as_retriever(search_kwargs={'k': 1}),\n",
    "                                return_source_documents=True,\n",
    "                                chain_type_kwargs={'prompt': qa_prompt}\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55c853b4-a17d-4040-8a0a-7a5fc088ecdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the ChatBot! Type 'exit' to end the conversation.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User     :  What is the Name of the university that Skandar is currently studying at?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94mAssistant:Skandar is currently studying at ESI (Highest School of Computer Science in Algeria).\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User     :  Can you tell me about skandar experience in hackathons?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94mAssistant:Skandar has participated in several hackathons, including the 2023 IWD Datathon in Algiers where he won first place award.\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User     :  Does Skandar knows kotlin?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94mAssistant:I don't know whether Skandar knows Kotlin or not, as this information is not provided in the given text.\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User     :  what is skandar currently looking for? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94mAssistant:Skandar is currently looking for a final year graduation internship to make a strong start to his career.\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User     :  Can you give me a summary of skandar's skills?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94mAssistant:Skandar has experience in database management systems (Oracle), Linux, shell scripting (Bash/Zsh), Git, Docker, software testing, time management, teamwork, leadership, problem-solving, documentation, public speaking, and has participated in hackathons such as the 2023 IWD Datathon Algiers. He is proficient in Arabic, English, and French.\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User     :  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[93mThank you for using the chatbot!\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def print_colored(text, color, style=\"\"):\n",
    "    styles = {\n",
    "        \"bold\": \"\\033[1m\",\n",
    "        \"reset\": \"\\033[0m\"\n",
    "    }\n",
    "    colors = {\n",
    "        \"red\": \"\\033[91m\",\n",
    "        \"green\": \"\\033[92m\",\n",
    "        \"yellow\": \"\\033[93m\",\n",
    "        \"blue\": \"\\033[94m\",\n",
    "        \"purple\": \"\\033[95m\",\n",
    "        \"cyan\": \"\\033[96m\",\n",
    "        \"white\": \"\\033[97m\",\n",
    "        \"reset\": \"\\033[0m\"\n",
    "    }\n",
    "    return f\"{styles.get(style, '')}{colors[color]}{text}{colors['reset']}{styles.get('reset', '')}\"\n",
    "\n",
    "print(\"Welcome to the ChatBot! Type 'exit' to end the conversation.\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"User     : \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        print(print_colored(\"Thank you for using the chatbot!\", \"yellow\", \"bold\"))\n",
    "        break\n",
    "    \n",
    "    # Simulate the assistant's response (you can replace this with your logic)\n",
    "    assistant_response = qa_bot({'query': user_input})[\"result\"]\n",
    "    print(print_colored(\"Assistant:\" + assistant_response, \"blue\", \"bold\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0041cded-6d39-471e-b7e8-085aa036d656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What prompts Victor Frankenstein to delve into scientific experimentation?\n",
    "# Describe the appearance of the creature that Victor brings to life.\n",
    "# How does Victor react when he sees the creature for the first time after its creation?\n",
    "# Why does the creature want a companion?\n",
    "# What happens to Victor Frankenstein in the end?\n",
    "# What happened to the creature in the end?\n",
    "# Who wrote the novel?\n",
    "# How does the creature learn about the world?\n",
    "# What is the subtitle of the novel?\n",
    "\n",
    "# ______________________________\n",
    "# What is the Name of the university that Skandar is currently studying at?\n",
    "# Can you tell me about skandar experience in hackathons?\n",
    "# Does Skandar knows kotlin?\n",
    "# what is skandar looking for? \n",
    "# Can you give me a summary of skandar's skills?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419e5c4e-e782-4bb9-8573-de4c7f51d0cc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Some Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aa3304-9c7c-4cd6-a2b6-3ff469cb871b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Skandar's CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec03e00-b42a-49da-b741-503d53dc3a32",
   "metadata": {},
   "source": [
    "![image.png](./Tests/cv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b1ae3c-4cea-415c-ac96-4788a4a00edd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Frankenstein novel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb210ce6-83f4-48ed-b800-c6fbf076b589",
   "metadata": {},
   "source": [
    "![image.png](./Tests/novel.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
